{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAMYBdu5retC5/0oEe2wI2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esthel7/ai/blob/master/predict_epidemic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MztFWLouXzO3"
      },
      "outputs": [],
      "source": [
        "#사용할 라이브러리\n",
        "\n",
        "from keras.models import Sequential #sequential 모델 불러오기\n",
        "from keras.layers import SimpleRNN, Dense #RNN은 순환 신경망, simpleRNN은 간단한 순환 신경망\n",
        "#순환 신경망은 이전의 연속된 데이터 사용하여 이후의 값 예측\n",
        "#Dense는 각 레이어에서의 뉴런의 수\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler #MinMaxScale는 정규화함수, sklearn 라이브러리 속에 있음\n",
        "from sklearn.metrics import mean_squared_error #mean_squared_error는 정확도 계산 위해 오차값 계산\n",
        "from sklearn.model_selection import train_test_split #데이터를 학습데이터와 검증데이터로 나눔(성능측정위함)\n",
        "import math #수학 계산\n",
        "import numpy as np #수학 계산 라이브러리를 np 이름으로 불러옴\n",
        "import matplotlib.pyplot as plt #그래프 그리기 위함\n",
        "from pandas import read_csv #pandas는 데이터 잘 처리하도록하는 라이브러리, csv 파일 불러옴"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#깃허브 데이터 가져오기\n",
        "\n",
        "!git clone https://github.com/yhlee1627/deeplearning.git #mnist는 keras 안의 데이터, git은 외부데이터\n",
        "dataframe=read_csv('/content/deeplearning/corona_daily.csv',usecols=[3],engine='python',skipfooter=3)\n",
        "#해당 git의 deeplearning파트에서 corona_daily.csv 불러오기\n",
        "#usecols는 해당 열만 불러오는 것으로, 4번째 열만 사용\n",
        "\n",
        "print(dataframe)\n",
        "dataset=dataframe.values #데이터만 사용\n",
        "datatset=dataset.astype('float32') #데이터 정규화(0~1로 변환 = 성능 향상) 위해 실수로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZH_ezpPTRNj",
        "outputId": "ee1bd75b-812e-44c8-f58e-b0b15f86daef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deeplearning'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n",
            "     Confirmed\n",
            "0           24\n",
            "1           24\n",
            "2           27\n",
            "3           27\n",
            "4           28\n",
            "..         ...\n",
            "107      11190\n",
            "108      11206\n",
            "109      11225\n",
            "110      11265\n",
            "111      11344\n",
            "\n",
            "[112 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 정규화 및 분류\n",
        "\n",
        "scaler=MinMaxScaler(feature_range=(0,1)) #데이터를 0~1사이로 정규화하기 위한 함수\n",
        "Dataset=scaler.fit_transform(dataset) #데이터 정규화\n",
        "train_data, test_data=train_test_split(Dataset, test_size=0.2, shuffle=False) \n",
        "#학습 데이터, 테스트 데이터로 나눔. 테스트 데이터를 20%. 성능 정확히 측정하기 위함\n",
        "#shuffle은 무작위 추출. 코로나 데이터를 예측하기 위함으로 무작위 추출이 아닌 앞선 데이터만 학습 데이터로\n",
        "\n",
        "print(len(train_data), len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMD5wxvhV1W4",
        "outputId": "eca23a5c-51cf-4f76-dd61-ef001046bdfb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 형태 변경하기\n",
        "\n",
        "def create_dataset(dataset, look_back): #원래의 데이터, 연속되는 데이터의 개수\n",
        "  x_data=[]\n",
        "  y_data=[]\n",
        "  for i in range(len(dataset)-look_back):\n",
        "    data=dataset[i:(i+look_back),0]\n",
        "    x_data.append(data)\n",
        "    y_data.append(dataset[i+look_back,0])\n",
        "  return np.array(x_data), np.array(y_data) #배열로 변환"
      ],
      "metadata": {
        "id": "PSWrPf7BXGrL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 데이터 생성하기\n",
        "\n",
        "look_back=3 \n",
        "#며칠동안 연속된 데이터를 사용할 지 지정\n",
        "#오래된 날짜를 한번에 학습할 경우 오류 생길 가능성 많음, 3일마다 한번씩 예측해서 학습시키기\n",
        "#1~3일로 4일 예측, 2~4일로 5일 예측 ...\n",
        "\n",
        "x_train, y_train=create_dataset(train_data, look_back)\n",
        "x_test, y_test=create_dataset(test_data, look_back)\n",
        "print(x_train.shape, y_train.shape) #x_train은 3개씩 86줄\n",
        "print(x_test.shape, y_test.shape) #x_test는 3개씩  20줄"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CNJBK_KmSMP",
        "outputId": "8410e857-7a85-4c56-d496-56b2d9347660"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(86, 3) (86,)\n",
            "(20, 3) (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#인공지능 모델에 넣어줄 형태로 변환하기\n",
        "\n",
        "X_train=np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1])) #형태 바꿔주는 reshape 함수\n",
        "#원래 데이터인 x_train(86줄)을 1*3(x_train.shape[1])로 만들기 (2차원에서 3차원으로)\n",
        "\n",
        "X_test=np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "print(X_train.shape) #1*3으로 구성된 데이터가 86개\n",
        "print(X_test.shape) #1*3으로 구성된 데이터가 20개"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qKE36gvn0ob",
        "outputId": "4b46df0e-b7ac-40b5-ed97-b7f4473a1c14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(86, 1, 3)\n",
            "(20, 1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#인공지능 모델\n",
        "\n",
        "model=Sequential() #순환신경망은 레이어들이 선형으로 연결된 모습이라 sequential로 설정\n",
        "model.add(SimpleRNN(3, input_shape=(1, look_back))) #뉴런의 수는 3개, input data로 1*(look_back)값 넣기\n",
        "model.add(Dense(1, activation=\"linear\")) #최종 예측값은 연속된 데이터 이후 값&1개이므로 1개 노드로 구성\n",
        "model.compile(loss='mse', optimizer='adam') #계산방법 결정, 손실함수는 mse사용(평균 제곱 오차, 음수계산때문)\n",
        "#optimizer는 오차 줄이기, adam 사용\n",
        "\n",
        "model.summary() #모델이 어떻게 구성되었는지 살펴보기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4EoPsooqImh",
        "outputId": "ec01d04a-3567-4076-d322-2cd18f6bd0b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 3)                 21        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25\n",
            "Trainable params: 25\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습시키기\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1)\n",
        "#입력데이터, 출력데이터, 학습반복수, 한번에 학습시킬 데이터 양\n",
        "#verbose 0은 아무런 표시 하지 않음, 1은 진행 사항 알려줌, 2는 학습 결과 알려줌 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naK_G8S4tleh",
        "outputId": "f674694b-56f2-4602-f576-1df72954271a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "86/86 [==============================] - 1s 2ms/step - loss: 0.7673\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.4228\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.1997\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0942\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0447\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0317\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0264\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0213\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0171\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0133\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0101\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0075\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0039\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0027\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0010\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 7.8793e-04\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 6.5300e-04\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 5.7073e-04\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 5.3322e-04\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 5.1472e-04\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 5.0016e-04\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.9420e-04\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.9546e-04\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.8923e-04\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.8740e-04\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.8184e-04\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.7249e-04\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.7269e-04\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.7340e-04\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.6181e-04\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.6698e-04\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.7301e-04\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.7193e-04\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.7050e-04\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.5373e-04\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.4633e-04\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.5505e-04\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.5892e-04\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.3208e-04\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.3631e-04\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.3842e-04\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.3858e-04\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.1627e-04\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.1595e-04\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.2403e-04\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.6442e-04\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.1876e-04\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.2243e-04\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.2739e-04\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.1438e-04\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.1895e-04\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.0252e-04\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.1045e-04\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.0784e-04\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.1108e-04\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 3.8614e-04\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.8931e-04\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.5980e-04\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.1721e-04\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 3.7527e-04\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.8037e-04\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.0605e-04\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 4.0135e-04\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 3.8389e-04\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 4.1523e-04\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.8165e-04\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.5603e-04\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.5994e-04\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.4988e-04\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.5054e-04\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.6242e-04\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.5110e-04\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.0902e-04\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.6079e-04\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.6722e-04\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.3128e-04\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.5202e-04\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.3757e-04\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.4186e-04\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.2927e-04\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.3241e-04\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.4591e-04\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.0160e-04\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.1052e-04\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.1102e-04\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.9906e-04\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 3.0825e-04\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.0385e-04\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.8684e-04\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.9508e-04\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.2336e-04\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 3.4313e-04\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.7805e-04\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.8957e-04\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 2.9531e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f20a80d90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 예측하기\n",
        "\n",
        "trainPredict=model.predict(X_train) #모델이 결괏값 생성하는 predict 함수, 반환값은 0~1 사이\n",
        "testPredict=model.predict(X_test)\n",
        "TrainPredict=scaler.inverse_transform(trainPredict) #0~1 사이의 값을 실제 데이터로 변환 - scaler 함수\n",
        "Y_train=scaler.inverse_transform([y_train])\n",
        "TestPredict=scaler.inverse_transform(testPredict)\n",
        "Y_test=scaler.inverse_transform([y_test])"
      ],
      "metadata": {
        "id": "I05YnSE1uKhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b04d1ed-0b7c-4fb9-ac51-102fd6b749b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델의 정확도 살펴보기\n",
        "\n",
        "trainScore=math.sqrt(mean_squared_error(Y_train[0], TrainPredict[:,0])) #sqrt는 루트\n",
        "#mead_squared_error는 정확도 계산 위해 오차값 계산 (실제값과 예측값 비교)\n",
        "#Y_train[0]은 실제 정답값 전체\n",
        "\n",
        "print('Train Score: %.2f RMSE' %(trainScore)) #학습데이터의 오차값\n",
        "testScore=math.sqrt(mean_squared_error(Y_test[0], TestPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' %(testScore)) #테스트데이터의 오차값"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6O8SqcUiy09",
        "outputId": "06970c54-1ea9-4e54-eb7e-7d4f5d4116c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Score: 196.96 RMSE\n",
            "Test Score: 323.84 RMSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#결과를 그래프로 확인\n",
        "\n",
        "trainPredictPlot=np.empty_like(dataset, dtype='float32') #dataset(float)과 동일한 크기의 빈 배열 만들기\n",
        "trainPredictPlot[:,:]=np.nan #nan을 써서 값 없음, 그래프 그릴 도화지 깨끗하게 만들기 위함\n",
        "trainPredictPlot[look_back:len(TrainPredict)+look_back, :]=TrainPredict\n",
        "#1~3일차를 통해 4일차 예측한게 첫 데이터이므로, look_back만큼 더한 값으로 시작\n",
        "\n",
        "testPredictPlot=np.empty_like(dataset, dtype='float32')\n",
        "testPredictPlot[:,:]=np.nan\n",
        "testPredictPlot[len(TrainPredict)+(look_back)*2:len(dataset),:]=TestPredict\n",
        "#처음 3일(look_back) 후 trainPredict, 3일 후 testPrecit 이므로 look_back 2번 곲해준 값 더하기\n",
        "\n",
        "plt.plot(dataset) #그래프로 그리기\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show() #화면에 나타내기\n",
        "\n",
        "#파란선은 실제 데이터, 주황색은 학습 데이터, 초록색은 예측 데이터"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NVNlQPdvkPcs",
        "outputId": "63c5a4a6-1f60-4664-e308-aad35da85cf0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}